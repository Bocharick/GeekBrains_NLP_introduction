{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# В предыдущей серии\n",
    "\n",
    "\n",
    "<img src=\"images/RNNCompar.png\"/>\n",
    "\n",
    "\n",
    "Мы посмотрели на задачу классификации текстов. Но есть ряд более сильных подходов, которые лучше показывать через задачу генерации\n",
    "\n",
    "\n",
    "# Генерация текстов, encoder-decoder\n",
    "\n",
    "<img src=\"images/EncDec.png\"/>\n",
    "\n",
    "\n",
    "Данная архитектура называется seq2seq, простыми словами выглядит она следующим образом:\n",
    "<img src=\"images/seq2seq.png\"/>\n",
    "\n",
    "\n",
    "эту модель можно строить на уровне слов и на уровне токенов. Попробуем обучить на уровне токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.2.0\n",
      "tensorflow.keras version: 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"tensorflow version:\", tf.__version__)\n",
    "print(\"tensorflow.keras version:\", tf.keras.__version__)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 100 # 30\n",
    "latent_dim = 256\n",
    "num_samples = 20000\n",
    "# data_path = 'data/fra-eng/fra.txt'\n",
    "data_path = 'data/rus-eng/rus.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем из текстов токены и делаем one-hot вектора на каждый токен\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    random.shuffle(lines)\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 13s 51ms/step - loss: 0.8904 - accuracy: 0.8088 - val_loss: 0.6485 - val_accuracy: 0.8252\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.5844 - accuracy: 0.8446 - val_loss: 0.5384 - val_accuracy: 0.8511\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.5027 - accuracy: 0.8586 - val_loss: 0.4868 - val_accuracy: 0.8617\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 11s 45ms/step - loss: 0.4675 - accuracy: 0.8661 - val_loss: 0.4608 - val_accuracy: 0.8676\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.4468 - accuracy: 0.8710 - val_loss: 0.4445 - val_accuracy: 0.8711\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.4320 - accuracy: 0.8747 - val_loss: 0.4311 - val_accuracy: 0.8745\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.4197 - accuracy: 0.8780 - val_loss: 0.4208 - val_accuracy: 0.8776\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.4090 - accuracy: 0.8807 - val_loss: 0.4104 - val_accuracy: 0.8798\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 12s 48ms/step - loss: 0.4010 - accuracy: 0.8829 - val_loss: 0.4019 - val_accuracy: 0.8825\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.3901 - accuracy: 0.8857 - val_loss: 0.3936 - val_accuracy: 0.8849\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.3819 - accuracy: 0.8878 - val_loss: 0.3847 - val_accuracy: 0.8874\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.3738 - accuracy: 0.8903 - val_loss: 0.3782 - val_accuracy: 0.8891\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.3667 - accuracy: 0.8924 - val_loss: 0.3708 - val_accuracy: 0.8912\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.3594 - accuracy: 0.8944 - val_loss: 0.3644 - val_accuracy: 0.8926\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.3523 - accuracy: 0.8963 - val_loss: 0.3583 - val_accuracy: 0.8949\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.3459 - accuracy: 0.8982 - val_loss: 0.3518 - val_accuracy: 0.8969\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.3395 - accuracy: 0.9001 - val_loss: 0.3460 - val_accuracy: 0.8980\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.3334 - accuracy: 0.9018 - val_loss: 0.3413 - val_accuracy: 0.8994\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 11s 45ms/step - loss: 0.3275 - accuracy: 0.9034 - val_loss: 0.3358 - val_accuracy: 0.9013\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.3219 - accuracy: 0.9050 - val_loss: 0.3311 - val_accuracy: 0.9025\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.3163 - accuracy: 0.9065 - val_loss: 0.3280 - val_accuracy: 0.9036\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.3110 - accuracy: 0.9080 - val_loss: 0.3225 - val_accuracy: 0.9048\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.3051 - accuracy: 0.9097 - val_loss: 0.3166 - val_accuracy: 0.9069\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.2997 - accuracy: 0.9112 - val_loss: 0.3119 - val_accuracy: 0.9079\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.2948 - accuracy: 0.9126 - val_loss: 0.3098 - val_accuracy: 0.9088\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.2905 - accuracy: 0.9137 - val_loss: 0.3055 - val_accuracy: 0.9101\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.2863 - accuracy: 0.9149 - val_loss: 0.3035 - val_accuracy: 0.9106\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.2821 - accuracy: 0.9161 - val_loss: 0.2998 - val_accuracy: 0.9115\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.2781 - accuracy: 0.9171 - val_loss: 0.2970 - val_accuracy: 0.9122\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.2743 - accuracy: 0.9182 - val_loss: 0.2944 - val_accuracy: 0.9127\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.2708 - accuracy: 0.9191 - val_loss: 0.2930 - val_accuracy: 0.9135\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 11s 45ms/step - loss: 0.2673 - accuracy: 0.9201 - val_loss: 0.2892 - val_accuracy: 0.9146\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.2638 - accuracy: 0.9211 - val_loss: 0.2887 - val_accuracy: 0.9147\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.2607 - accuracy: 0.9220 - val_loss: 0.2867 - val_accuracy: 0.9152\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.2576 - accuracy: 0.9228 - val_loss: 0.2851 - val_accuracy: 0.9158\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.2545 - accuracy: 0.9237 - val_loss: 0.2838 - val_accuracy: 0.9163\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.2517 - accuracy: 0.9244 - val_loss: 0.2826 - val_accuracy: 0.9166\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.2487 - accuracy: 0.9252 - val_loss: 0.2824 - val_accuracy: 0.9165\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.2449 - accuracy: 0.9266 - val_loss: 0.2784 - val_accuracy: 0.9182\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.2411 - accuracy: 0.9278 - val_loss: 0.2778 - val_accuracy: 0.9185\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.2382 - accuracy: 0.9286 - val_loss: 0.2766 - val_accuracy: 0.9191\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.2353 - accuracy: 0.9295 - val_loss: 0.2763 - val_accuracy: 0.9192\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.2326 - accuracy: 0.9302 - val_loss: 0.2749 - val_accuracy: 0.9194\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 12s 48ms/step - loss: 0.2305 - accuracy: 0.9308 - val_loss: 0.2746 - val_accuracy: 0.9197\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.2271 - accuracy: 0.9319 - val_loss: 0.2730 - val_accuracy: 0.9204\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.2243 - accuracy: 0.9327 - val_loss: 0.2728 - val_accuracy: 0.9207\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.2217 - accuracy: 0.9334 - val_loss: 0.2725 - val_accuracy: 0.9207\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.2189 - accuracy: 0.9343 - val_loss: 0.2729 - val_accuracy: 0.9206\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.2158 - accuracy: 0.9352 - val_loss: 0.2717 - val_accuracy: 0.9213\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.2131 - accuracy: 0.9361 - val_loss: 0.2723 - val_accuracy: 0.9211\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.2104 - accuracy: 0.9368 - val_loss: 0.2711 - val_accuracy: 0.9218\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.2079 - accuracy: 0.9376 - val_loss: 0.2708 - val_accuracy: 0.9221\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.2051 - accuracy: 0.9384 - val_loss: 0.2710 - val_accuracy: 0.9221\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.2026 - accuracy: 0.9392 - val_loss: 0.2705 - val_accuracy: 0.9227\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.2000 - accuracy: 0.9400 - val_loss: 0.2720 - val_accuracy: 0.9225\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1974 - accuracy: 0.9407 - val_loss: 0.2701 - val_accuracy: 0.9231\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 12s 47ms/step - loss: 0.1953 - accuracy: 0.9414 - val_loss: 0.2721 - val_accuracy: 0.9227\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.1929 - accuracy: 0.9421 - val_loss: 0.2724 - val_accuracy: 0.9228\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.1908 - accuracy: 0.9427 - val_loss: 0.2726 - val_accuracy: 0.9229\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.1889 - accuracy: 0.9432 - val_loss: 0.2733 - val_accuracy: 0.9229\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1868 - accuracy: 0.9439 - val_loss: 0.2752 - val_accuracy: 0.9226\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.1849 - accuracy: 0.9444 - val_loss: 0.2743 - val_accuracy: 0.9230\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1831 - accuracy: 0.9450 - val_loss: 0.2749 - val_accuracy: 0.9230\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1810 - accuracy: 0.9456 - val_loss: 0.2768 - val_accuracy: 0.9230\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.1805 - accuracy: 0.9457 - val_loss: 0.2771 - val_accuracy: 0.9229\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1779 - accuracy: 0.9464 - val_loss: 0.2776 - val_accuracy: 0.9231\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.1759 - accuracy: 0.9470 - val_loss: 0.2795 - val_accuracy: 0.9231\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.1742 - accuracy: 0.9476 - val_loss: 0.2809 - val_accuracy: 0.9229\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.1726 - accuracy: 0.9480 - val_loss: 0.2803 - val_accuracy: 0.9230\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1709 - accuracy: 0.9487 - val_loss: 0.2826 - val_accuracy: 0.9228\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.1696 - accuracy: 0.9491 - val_loss: 0.2846 - val_accuracy: 0.9224\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.1689 - accuracy: 0.9492 - val_loss: 0.2844 - val_accuracy: 0.9230\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.1665 - accuracy: 0.9499 - val_loss: 0.2862 - val_accuracy: 0.9226\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1653 - accuracy: 0.9503 - val_loss: 0.2877 - val_accuracy: 0.9230\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.1635 - accuracy: 0.9508 - val_loss: 0.2885 - val_accuracy: 0.9227\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 11s 45ms/step - loss: 0.1622 - accuracy: 0.9513 - val_loss: 0.2896 - val_accuracy: 0.9225\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.1608 - accuracy: 0.9517 - val_loss: 0.2914 - val_accuracy: 0.9226\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1595 - accuracy: 0.9521 - val_loss: 0.2939 - val_accuracy: 0.9219\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.1586 - accuracy: 0.9523 - val_loss: 0.2930 - val_accuracy: 0.9228\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.1596 - accuracy: 0.9519 - val_loss: 0.2937 - val_accuracy: 0.9224\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1569 - accuracy: 0.9528 - val_loss: 0.2946 - val_accuracy: 0.9225\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1544 - accuracy: 0.9536 - val_loss: 0.2973 - val_accuracy: 0.9224\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.1535 - accuracy: 0.9538 - val_loss: 0.2973 - val_accuracy: 0.9222\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.1522 - accuracy: 0.9542 - val_loss: 0.2986 - val_accuracy: 0.9224\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.1509 - accuracy: 0.9546 - val_loss: 0.2997 - val_accuracy: 0.9226\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1502 - accuracy: 0.9547 - val_loss: 0.3004 - val_accuracy: 0.9224\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1491 - accuracy: 0.9551 - val_loss: 0.3038 - val_accuracy: 0.9219\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1481 - accuracy: 0.9554 - val_loss: 0.3052 - val_accuracy: 0.9220\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1470 - accuracy: 0.9558 - val_loss: 0.3064 - val_accuracy: 0.9219\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.1458 - accuracy: 0.9559 - val_loss: 0.3081 - val_accuracy: 0.9217\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1452 - accuracy: 0.9562 - val_loss: 0.3091 - val_accuracy: 0.9219\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.1442 - accuracy: 0.9565 - val_loss: 0.3098 - val_accuracy: 0.9219\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.1428 - accuracy: 0.9570 - val_loss: 0.3110 - val_accuracy: 0.9217\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.1474 - accuracy: 0.9554 - val_loss: 0.3125 - val_accuracy: 0.9214\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.1425 - accuracy: 0.9570 - val_loss: 0.3137 - val_accuracy: 0.9215\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1413 - accuracy: 0.9573 - val_loss: 0.3148 - val_accuracy: 0.9213\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1402 - accuracy: 0.9577 - val_loss: 0.3185 - val_accuracy: 0.9209\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.1391 - accuracy: 0.9581 - val_loss: 0.3168 - val_accuracy: 0.9218\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1384 - accuracy: 0.9582 - val_loss: 0.3182 - val_accuracy: 0.9213\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 12s 46ms/step - loss: 0.1374 - accuracy: 0.9586 - val_loss: 0.3199 - val_accuracy: 0.9213\n",
      "-\n",
      "Input sentence: I'm not done with you.\n",
      "Decoded sentence: Я не был таким веде.\n",
      "\n",
      "-\n",
      "Input sentence: I read your letter to my family.\n",
      "Decoded sentence: Я подумал, что ты не понимаешь.\n",
      "\n",
      "-\n",
      "Input sentence: He is always willing to help others.\n",
      "Decoded sentence: Он поступил твой проблемой к поездел в адном.\n",
      "\n",
      "-\n",
      "Input sentence: Tom will never win.\n",
      "Decoded sentence: Том поможет нам.\n",
      "\n",
      "-\n",
      "Input sentence: Tom moved close to Mary.\n",
      "Decoded sentence: Том поставил учительмато от себе.\n",
      "\n",
      "-\n",
      "Input sentence: This soup needs more salt.\n",
      "Decoded sentence: Это самое времени на толекоров.\n",
      "\n",
      "-\n",
      "Input sentence: Boston is beautiful.\n",
      "Decoded sentence: Просто сделать это.\n",
      "\n",
      "-\n",
      "Input sentence: We prefer to travel by train.\n",
      "Decoded sentence: Мы подождали печемьния к терерци.\n",
      "\n",
      "-\n",
      "Input sentence: Wait a sec.\n",
      "Decoded sentence: Позвони меня.\n",
      "\n",
      "-\n",
      "Input sentence: They rented an apartment.\n",
      "Decoded sentence: Они не могут возресть.\n",
      "\n",
      "-\n",
      "Input sentence: You need to sit.\n",
      "Decoded sentence: Вы могли бы поговорить об этом.\n",
      "\n",
      "-\n",
      "Input sentence: Many people do not trust the government.\n",
      "Decoded sentence: Многие люди не в следующем восте.\n",
      "\n",
      "-\n",
      "Input sentence: We'll wait.\n",
      "Decoded sentence: Мы сейчас уже пример.\n",
      "\n",
      "-\n",
      "Input sentence: You can't tame a wolf.\n",
      "Decoded sentence: Можете не быть дома.\n",
      "\n",
      "-\n",
      "Input sentence: Let's go for a walk after lunch.\n",
      "Decoded sentence: Давайте не будем себе уходить.\n",
      "\n",
      "-\n",
      "Input sentence: They're all talking about his death.\n",
      "Decoded sentence: Они не могут вас за тебе спервой.\n",
      "\n",
      "-\n",
      "Input sentence: Did you get someone to look after the child?\n",
      "Decoded sentence: Ты подумал Тома, если хочешь?\n",
      "\n",
      "-\n",
      "Input sentence: Why didn't your wash your hands?\n",
      "Decoded sentence: Почему ты не видел Тома?\n",
      "\n",
      "-\n",
      "Input sentence: Tomorrow's your day off.\n",
      "Decoded sentence: Скажите Тому, чтобы он тебя поступил.\n",
      "\n",
      "-\n",
      "Input sentence: You look depressed. Did something happen?\n",
      "Decoded sentence: Ты должен встретиться с Томом.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: It appears to me that we misunderstand him.\n",
      "Decoded sentence: Давай снего общимило в покине и настолько.\n",
      "\n",
      "-\n",
      "Input sentence: Tom and I are alone.\n",
      "Decoded sentence: Мы с Томом оба из чёртого.\n",
      "\n",
      "-\n",
      "Input sentence: I've bought a car.\n",
      "Decoded sentence: Я видела старые для.\n",
      "\n",
      "-\n",
      "Input sentence: Tom is no saint.\n",
      "Decoded sentence: Том был воспитан.\n",
      "\n",
      "-\n",
      "Input sentence: I have few books.\n",
      "Decoded sentence: Я никогда не была поговорить.\n",
      "\n",
      "-\n",
      "Input sentence: Who ran for president that year?\n",
      "Decoded sentence: Кто вас с Томом постарала?\n",
      "\n",
      "-\n",
      "Input sentence: You're not giving me what I need.\n",
      "Decoded sentence: Ты не мог бы подарить на меня помощи.\n",
      "\n",
      "-\n",
      "Input sentence: I'm in constant danger.\n",
      "Decoded sentence: Я нашёл вами.\n",
      "\n",
      "-\n",
      "Input sentence: That's what makes it so difficult.\n",
      "Decoded sentence: Это произошло три дня назад.\n",
      "\n",
      "-\n",
      "Input sentence: Don't be afraid of making mistakes when you speak English.\n",
      "Decoded sentence: Не позволяйте безумном и своло нет возменает.\n",
      "\n",
      "-\n",
      "Input sentence: I have blonde hair.\n",
      "Decoded sentence: Я никогда не был убива.\n",
      "\n",
      "-\n",
      "Input sentence: Tom plans to just stay at home.\n",
      "Decoded sentence: Том попросил меня прийти завтра.\n",
      "\n",
      "-\n",
      "Input sentence: I shouldn't have lied to you.\n",
      "Decoded sentence: Я не могу поверить с вами.\n",
      "\n",
      "-\n",
      "Input sentence: Why can't we all just live in peace?\n",
      "Decoded sentence: Почему ты не видел Тома в постели?\n",
      "\n",
      "-\n",
      "Input sentence: He's washing your car.\n",
      "Decoded sentence: Он не может ситьёт.\n",
      "\n",
      "-\n",
      "Input sentence: Take the medicine every hour.\n",
      "Decoded sentence: После делай, и Том.\n",
      "\n",
      "-\n",
      "Input sentence: No security system is foolproof.\n",
      "Decoded sentence: Пожалуйста, закроили свою доманию росторание.\n",
      "\n",
      "-\n",
      "Input sentence: Tom doesn't have the necessary skills for that job.\n",
      "Decoded sentence: Том не сказал мне, что его уже здесь.\n",
      "\n",
      "-\n",
      "Input sentence: Take the dog for a walk.\n",
      "Decoded sentence: После делай я так мне.\n",
      "\n",
      "-\n",
      "Input sentence: I slept with my clothes on.\n",
      "Decoded sentence: Я подумал, что ты это сделаешь.\n",
      "\n",
      "-\n",
      "Input sentence: Lock your doors.\n",
      "Decoded sentence: Посмотрите на наше.\n",
      "\n",
      "-\n",
      "Input sentence: It's made of paper.\n",
      "Decoded sentence: Это не так много.\n",
      "\n",
      "-\n",
      "Input sentence: I'm afraid to go alone.\n",
      "Decoded sentence: Я настолько часыв изман.\n",
      "\n",
      "-\n",
      "Input sentence: I'd prefer that black one over there.\n",
      "Decoded sentence: Я рассказал Тому о своих семьей.\n",
      "\n",
      "-\n",
      "Input sentence: Did you know Tom wanted to do that?\n",
      "Decoded sentence: Ты знал, что Том не любит тебя?\n",
      "\n",
      "-\n",
      "Input sentence: Tom sold it to me.\n",
      "Decoded sentence: Том попросил у какой-то.\n",
      "\n",
      "-\n",
      "Input sentence: When will the roses in your garden bloom?\n",
      "Decoded sentence: Когда ты в последний раз ходил здонит?\n",
      "\n",
      "-\n",
      "Input sentence: I thought Tom would sleep until noon.\n",
      "Decoded sentence: Я думал, Том из Бостоне нет.\n",
      "\n",
      "-\n",
      "Input sentence: We are about to sit down to dinner.\n",
      "Decoded sentence: Мы подождали нечи уходить.\n",
      "\n",
      "-\n",
      "Input sentence: That's what Tom does to those he doesn't like.\n",
      "Decoded sentence: Это произошло три часа, что и Том вмёт.\n",
      "\n",
      "-\n",
      "Input sentence: I had to speak French.\n",
      "Decoded sentence: Я понятия не имел, что ты делаешь.\n",
      "\n",
      "-\n",
      "Input sentence: I knew that Tom wouldn't be late.\n",
      "Decoded sentence: Я знал, что Том не очень хорошо себя чувствует.\n",
      "\n",
      "-\n",
      "Input sentence: I baked some cookies for Tom.\n",
      "Decoded sentence: Я понятия не имел, что ты делаешь Мэри.\n",
      "\n",
      "-\n",
      "Input sentence: Tom told Mary to try harder.\n",
      "Decoded sentence: Том сказал Мэри сделать это несколько одно.\n",
      "\n",
      "-\n",
      "Input sentence: Which do you drink for breakfast, tea or coffee?\n",
      "Decoded sentence: Как думаешь, куда Том молон стоя?\n",
      "\n",
      "-\n",
      "Input sentence: Please buy me three pens.\n",
      "Decoded sentence: Пожалуйста, не говори моей побожнь!\n",
      "\n",
      "-\n",
      "Input sentence: I don't think you can eat that.\n",
      "Decoded sentence: Не думаю, что кто-то ещё.\n",
      "\n",
      "-\n",
      "Input sentence: You lied to Tom and me.\n",
      "Decoded sentence: Ты должен вернуться в полтретьего.\n",
      "\n",
      "-\n",
      "Input sentence: She's turning red.\n",
      "Decoded sentence: Она вышла замужем.\n",
      "\n",
      "-\n",
      "Input sentence: Didn't you know that Tom was Mary's brother?\n",
      "Decoded sentence: Ты не знал, что Том не любит это произивится?\n",
      "\n",
      "-\n",
      "Input sentence: Tom is hoping to do that, isn't he?\n",
      "Decoded sentence: Том всё ещё не собирается с Мэри.\n",
      "\n",
      "-\n",
      "Input sentence: I don't think Tom knows Mary is still in Boston.\n",
      "Decoded sentence: Не думаю, что Тому надо было сказать Мэри, чтобы он оставил меня в покое.\n",
      "\n",
      "-\n",
      "Input sentence: Would you like a newspaper or magazine?\n",
      "Decoded sentence: Думаешь, Том просил меня сердёт?\n",
      "\n",
      "-\n",
      "Input sentence: I have a rough idea where it is.\n",
      "Decoded sentence: Я понятия не имел, что ты делаешь.\n",
      "\n",
      "-\n",
      "Input sentence: She complained about my low salary.\n",
      "Decoded sentence: Она почти всегда ужинали, не так ли?\n",
      "\n",
      "-\n",
      "Input sentence: I'm prudent.\n",
      "Decoded sentence: Я сейчас в постене.\n",
      "\n",
      "-\n",
      "Input sentence: Tom is your teacher.\n",
      "Decoded sentence: Том - наш читат.\n",
      "\n",
      "-\n",
      "Input sentence: You're always right.\n",
      "Decoded sentence: Ты всего не было.\n",
      "\n",
      "-\n",
      "Input sentence: Does Tom wear glasses?\n",
      "Decoded sentence: Том возвелен в школь?\n",
      "\n",
      "-\n",
      "Input sentence: He lives in Tokyo now.\n",
      "Decoded sentence: Он подождал меня до вас на рыбалку.\n",
      "\n",
      "-\n",
      "Input sentence: Tom threw a rock at one of my dogs.\n",
      "Decoded sentence: Том попросил меня прийти завтра.\n",
      "\n",
      "-\n",
      "Input sentence: It's the law now.\n",
      "Decoded sentence: Это не так много.\n",
      "\n",
      "-\n",
      "Input sentence: Try to be on time.\n",
      "Decoded sentence: Позвони мне петь.\n",
      "\n",
      "-\n",
      "Input sentence: Tom couldn't take his eyes off Mary.\n",
      "Decoded sentence: Том не может делать это остановить Мэри.\n",
      "\n",
      "-\n",
      "Input sentence: This is a fact.\n",
      "Decoded sentence: Это не так.\n",
      "\n",
      "-\n",
      "Input sentence: I'm going to the concert tomorrow.\n",
      "Decoded sentence: Я подумал, что ты это сделаешь.\n",
      "\n",
      "-\n",
      "Input sentence: I went to school with your dad.\n",
      "Decoded sentence: Я сказал Тому, чтобы он не просит.\n",
      "\n",
      "-\n",
      "Input sentence: Mary was convinced that she would never get married.\n",
      "Decoded sentence: Мой отец не сделал на своей мама.\n",
      "\n",
      "-\n",
      "Input sentence: I haven't yet been paid for doing that.\n",
      "Decoded sentence: Я не могу поверить, что Том это сделал.\n",
      "\n",
      "-\n",
      "Input sentence: You're our neighbor.\n",
      "Decoded sentence: Вы настоящий.\n",
      "\n",
      "-\n",
      "Input sentence: I didn't recognize you at first.\n",
      "Decoded sentence: Я не понимаю по-французски.\n",
      "\n",
      "-\n",
      "Input sentence: He does not know how to behave at the table.\n",
      "Decoded sentence: Он не мог остаться с Томом доманда.\n",
      "\n",
      "-\n",
      "Input sentence: He has a cold.\n",
      "Decoded sentence: Он не может ситьёт.\n",
      "\n",
      "-\n",
      "Input sentence: Be merciful.\n",
      "Decoded sentence: Попробуйте ещё раз.\n",
      "\n",
      "-\n",
      "Input sentence: Do you have lots of friends?\n",
      "Decoded sentence: Ты ведь не выиграешь?\n",
      "\n",
      "-\n",
      "Input sentence: We took showers.\n",
      "Decoded sentence: Мы все знаем, что сделаю.\n",
      "\n",
      "-\n",
      "Input sentence: It's a small town.\n",
      "Decoded sentence: Это не так уж собрал.\n",
      "\n",
      "-\n",
      "Input sentence: We want what we want.\n",
      "Decoded sentence: Мы должны делать это одному.\n",
      "\n",
      "-\n",
      "Input sentence: The new hall is double the size of the old one.\n",
      "Decoded sentence: Полиция обедают докательной принести в автобус.\n",
      "\n",
      "-\n",
      "Input sentence: Give me what I want.\n",
      "Decoded sentence: Послушай, Том.\n",
      "\n",
      "-\n",
      "Input sentence: I gave Tom all my money.\n",
      "Decoded sentence: Я сказал Тому, чтобы он не просит.\n",
      "\n",
      "-\n",
      "Input sentence: Do you think Tom is lying to us?\n",
      "Decoded sentence: Думаешь, Том попросит?\n",
      "\n",
      "-\n",
      "Input sentence: What's your favorite flavor?\n",
      "Decoded sentence: Что ты хочешь сегодня?\n",
      "\n",
      "-\n",
      "Input sentence: I bought this camera for 25,000 yen.\n",
      "Decoded sentence: Я позвоню Тому и у тебя подождёт.\n",
      "\n",
      "-\n",
      "Input sentence: I'm not going to lie.\n",
      "Decoded sentence: Я не был у тебя разговаривал.\n",
      "\n",
      "-\n",
      "Input sentence: I said go home.\n",
      "Decoded sentence: Я сказал, что всё это сделал.\n",
      "\n",
      "-\n",
      "Input sentence: The police said they found Tom's fingerprints there.\n",
      "Decoded sentence: Полиция обедают докательной политоров на работе пригисов по сестрой.\n",
      "\n",
      "-\n",
      "Input sentence: Tom hasn't done much.\n",
      "Decoded sentence: Том не был не умерет.\n",
      "\n",
      "-\n",
      "Input sentence: Would you like to switch seats?\n",
      "Decoded sentence: Думаешь, Том пострадает?\n",
      "\n",
      "-\n",
      "Input sentence: I saw you staring at Tom.\n",
      "Decoded sentence: Я видел, как Том и Мэри.\n",
      "\n",
      "CPU times: user 28min 55s, sys: 16min 39s, total: 45min 34s\n",
      "Wall time: 23min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "#           epochs=5,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "# for seq_index in range(3):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но есть проблемы:\n",
    "- на длинных последовательностях результат будет не очень - быстро забывается контекст\n",
    "- хочется научить сеть смотреть в определенное место в прошлом при генерации\n",
    "\n",
    "attention\n",
    "\n",
    "<img src=\"images/Attention.png\"/>\n",
    "\n",
    "<img src=\"images/Attention2.png\"/>\n",
    "\n",
    "\n",
    "- h(t): скрытое состояние декодера\n",
    "- c(t): вектор контекста, который подается на вход\n",
    "- y(t): текущий таргет\n",
    "- $\\bar{h}(t)$: скрытое состояние attention\n",
    "- a(t): скор нормализации\n",
    "\n",
    "\n",
    "$$\\bar{h}(t)\\ =\\ tanh(W_c\\ [c_t,\\ h_t]) $$\n",
    "\n",
    "$$P(y_t|y_{<t},\\ x)\\ =\\ softmax(W_s\\ \\bar{h}_t) $$\n",
    "\n",
    "\n",
    "Зачем нужен скор нормализации? - пытаемся сравнить похожесть текущего скрытого состояния и скрытого состояния из прошлого и понять, на что обращать внимание\n",
    "\n",
    "\n",
    "$$a_t(s)\\ =\\ \\frac{exp(score(h_t,\\ \\bar{h}_s))}{\\sum_{i}\\ exp(score(h_t,\\ \\bar{h}_i)) }$$ \n",
    "\n",
    "\n",
    "<img src=\"images/scores.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поднимемся на уровень слов, чтобы можно было что-то более адекватное посчитать за адекватное время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "# data_path = 'data/fra-eng/fra.txt'\n",
    "data_path = 'data/rus-eng/rus.txt'\n",
    "num_samples = 20000\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "#     w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Zа-яА-Я?.!,¿]+\", \" \", w)\n",
    "    w = w.strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    random.shuffle(lines)\n",
    "\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(preprocess_sentence(input_text))\n",
    "    target_texts.append(preprocess_sentence(target_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392306"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tom has a very expensive watch.\\tУ Тома очень дорогие часы.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #5825025 (CK) & #7896926 (marafon)',\n",
       " \"It's Saturday.\\tСуббота.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2123580 (CK) & #2782593 (marafon)\",\n",
       " 'I liked your story.\\tМне понравилась Ваша история.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1887543 (CK) & #2810175 (marafon)',\n",
       " '\"Where are my glasses?\" \"You left them on the kitchen table.\"\\t\"Где мои очки?\" - \"Ты оставил их на кухонном столе\".\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2837572 (patgfisher) & #2843286 (odexed)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in1: Tom has a very expensive watch.\n",
      "targ1: У Тома очень дорогие часы.\n"
     ]
    }
   ],
   "source": [
    "in1, targ1, _ = lines[0].split(\"\\t\")\n",
    "print(\"in1:\", in1)\n",
    "print(\"targ1:\", targ1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> Tom has a very expensive watch . <end>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_sentence(in1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> У Тома очень дорогие часы . <end>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_sentence(targ1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor, inp_lang_tokenizer = tokenize(input_texts)\n",
    "target_tensor, targ_lang_tokenizer = tokenize(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.lstm(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "\n",
    "    \n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "    \n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.lstm(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 1.4935\n",
      "Epoch 2 Loss 1.2162\n",
      "Epoch 3 Loss 1.0737\n",
      "Epoch 4 Loss 0.9460\n",
      "Epoch 5 Loss 0.8178\n",
      "Epoch 6 Loss 0.6897\n",
      "Epoch 7 Loss 0.5722\n",
      "Epoch 8 Loss 0.4598\n",
      "Epoch 9 Loss 0.3557\n",
      "Epoch 10 Loss 0.2729\n",
      "Epoch 11 Loss 0.2114\n",
      "Epoch 12 Loss 0.1653\n",
      "Epoch 13 Loss 0.1340\n",
      "Epoch 14 Loss 0.1035\n",
      "Epoch 15 Loss 0.0814\n",
      "Epoch 16 Loss 0.0638\n",
      "Epoch 17 Loss 0.0522\n",
      "Epoch 18 Loss 0.0413\n",
      "Epoch 19 Loss 0.0343\n",
      "Epoch 20 Loss 0.0305\n",
      "Epoch 21 Loss 0.0265\n",
      "Epoch 22 Loss 0.0290\n",
      "Epoch 23 Loss 0.0268\n",
      "Epoch 24 Loss 0.0263\n",
      "Epoch 25 Loss 0.0205\n",
      "Epoch 26 Loss 0.0207\n",
      "Epoch 27 Loss 0.0318\n",
      "Epoch 28 Loss 0.0244\n",
      "Epoch 29 Loss 0.0200\n",
      "Epoch 30 Loss 0.0161\n",
      "Epoch 31 Loss 0.0136\n",
      "Epoch 32 Loss 0.0125\n",
      "Epoch 33 Loss 0.0125\n",
      "Epoch 34 Loss 0.0125\n",
      "Epoch 35 Loss 0.0140\n",
      "Epoch 36 Loss 0.0169\n",
      "Epoch 37 Loss 0.0217\n",
      "Epoch 38 Loss 0.0217\n",
      "Epoch 39 Loss 0.0161\n",
      "Epoch 40 Loss 0.0121\n",
      "Epoch 41 Loss 0.0097\n",
      "Epoch 42 Loss 0.0088\n",
      "Epoch 43 Loss 0.0081\n",
      "Epoch 44 Loss 0.0107\n",
      "Epoch 45 Loss 0.0202\n",
      "Epoch 46 Loss 0.0216\n",
      "Epoch 47 Loss 0.0148\n",
      "Epoch 48 Loss 0.0122\n",
      "Epoch 49 Loss 0.0102\n",
      "Epoch 50 Loss 0.0089\n",
      "Epoch 51 Loss 0.0078\n",
      "Epoch 52 Loss 0.0074\n",
      "Epoch 53 Loss 0.0100\n",
      "Epoch 54 Loss 0.0159\n",
      "Epoch 55 Loss 0.0160\n",
      "Epoch 56 Loss 0.0127\n",
      "Epoch 57 Loss 0.0107\n",
      "Epoch 58 Loss 0.0091\n",
      "Epoch 59 Loss 0.0079\n",
      "Epoch 60 Loss 0.0088\n",
      "Epoch 61 Loss 0.0083\n",
      "Epoch 62 Loss 0.0091\n",
      "Epoch 63 Loss 0.0097\n",
      "Epoch 64 Loss 0.0107\n",
      "Epoch 65 Loss 0.0131\n",
      "Epoch 66 Loss 0.0140\n",
      "Epoch 67 Loss 0.0124\n",
      "Epoch 68 Loss 0.0106\n",
      "Epoch 69 Loss 0.0094\n",
      "Epoch 70 Loss 0.0093\n",
      "Epoch 71 Loss 0.0089\n",
      "Epoch 72 Loss 0.0086\n",
      "Epoch 73 Loss 0.0131\n",
      "Epoch 74 Loss 0.0136\n",
      "Epoch 75 Loss 0.0095\n",
      "Epoch 76 Loss 0.0081\n",
      "Epoch 77 Loss 0.0067\n",
      "Epoch 78 Loss 0.0057\n",
      "Epoch 79 Loss 0.0053\n",
      "Epoch 80 Loss 0.0049\n",
      "Epoch 81 Loss 0.0054\n",
      "Epoch 82 Loss 0.0060\n",
      "Epoch 83 Loss 0.0088\n",
      "Epoch 84 Loss 0.0235\n",
      "Epoch 85 Loss 0.0173\n",
      "Epoch 86 Loss 0.0111\n",
      "Epoch 87 Loss 0.0079\n",
      "Epoch 88 Loss 0.0067\n",
      "Epoch 89 Loss 0.0063\n",
      "Epoch 90 Loss 0.0061\n",
      "Epoch 91 Loss 0.0053\n",
      "Epoch 92 Loss 0.0053\n",
      "Epoch 93 Loss 0.0054\n",
      "Epoch 94 Loss 0.0064\n",
      "Epoch 95 Loss 0.0078\n",
      "Epoch 96 Loss 0.0152\n",
      "Epoch 97 Loss 0.0194\n",
      "Epoch 98 Loss 0.0126\n",
      "Epoch 99 Loss 0.0080\n",
      "Epoch 100 Loss 0.0062\n",
      "CPU times: user 2h 36min 38s, sys: 30min 24s, total: 3h 7min 3s\n",
      "Wall time: 1h 45min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EPOCHS = 100\n",
    "for epoch in range(EPOCHS):\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые украденные функции для оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    fontdict = {'fontsize': 14}\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()\n",
    "    \n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random', 'f', 'char']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> good morning <end>\n",
      "Predicted translation: его собаки ? <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "translate(u'good morning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hi <end>\n",
      "Predicted translation: конечно ! <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hi how are you ? <end>\n",
      "Predicted translation: эй , ты зарабатываешь ? <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"hi how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> i m fine , and you ? <end>\n",
      "Predicted translation: я в этом , и ты ? <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"i'm fine, and you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate(\"If two witches were watching two watches which witch would watch which watch\".lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "<img src=\"images/transformer.png\"/>\n",
    "\n",
    "\n",
    "Идея в том, что каждое слово параллельно проходит через слои, изображенные на картинке.\n",
    "Некоторые из них — это стандартные fully-connected layers, некоторые — shortcut connections как в ResNet (там, где на картинке Add).\n",
    "\n",
    "\n",
    "Multi-head attention - это специальный новый слой, который дает возможность каждому входному вектору взаимодействовать с другими словами через attention mechanism, вместо передачи hidden state как в RNN или соседних слов как в CNN.\n",
    "\n",
    "\n",
    "<img src=\"images/mha.png\"/>\n",
    "\n",
    "\n",
    "<img src=\"images/AttTr.png\"/>\n",
    "\n",
    "\n",
    "Работа энкодера:\n",
    "\n",
    "\n",
    "Делаются эмбеддинги для всех слов предложения (вектора одинаковой размерности). Для примера пусть это будет предложение I am stupid. В эмбеддинг добавляется еще позиция слова в предложении.\n",
    "\n",
    "\n",
    "Берется вектор первого слова и вектор второго слова (I, am), подаются на однослойную сеть с одним выходом, которая выдает степень их похожести (скалярная величина). Эта скалярная величина умножается на вектор второго слова, получая его некоторую \"ослабленную\" на величину похожести копию.\n",
    "\n",
    "\n",
    "Вместо второго слова подается третье слово и делается тоже самое что в п.2. с той же самой сетью с теми же весами (для векторов I, stupid).\n",
    "\n",
    "\n",
    "Делая тоже самое для всех оставшихся слов предложения получаются их \"ослабленные\" (взвешенные) копии, которые выражают степень их похожести на первое слово. Далее эти все взвешенные вектора складываются друг с другом, получая один результирующий вектор размерности одного эмбединга:\n",
    "output=am * weight(I, am) + stupid * weight(I, stupid)\n",
    "\n",
    "\n",
    "Это механизм \"обычного\" attention.\n",
    "Так как оценка похожести слов всего одним способом (по одному критерию) считается недостаточной, тоже самое (п.2-4) повторяется несколько раз с другими весами. Типа одна один attention может определять похожесть слов по смысловой нагрузке, другой по грамматической, остальные еще как-то и т.п.\n",
    "\n",
    "\n",
    "На выходе п.5. получается несколько векторов, каждый из которых является взвешенной суммой всех остальных слов предложения относительно их похожести на первое слово (I). Конкантенируем этот вректор в один.\n",
    "\n",
    "\n",
    "Дальше ставится еще один слой линейного преобразования, уменьшающий размерность результата п.6. до размерности вектора одного эмбединга. Получается некое представление первого слова предложения, составленное из взвешенных векторов всех остальных слов предложения.\n",
    "\n",
    "\n",
    "Такой же процесс производится для всех других слов в предложении.\n",
    "\n",
    "\n",
    "Так как размерность выхода та же, то можно проделать все тоже самое еще раз (п.2-8), но вместо оригинальных эмбеддингов слов взять то, что получается после прохода через этот Multi-head attention, а нейросети аттеншенов внутри взять с другими весами (веса между слоями не общие). И таких слоев можно сделать много (у гугла 6). Однако между первым и вторым слоем добавляется еще полносвязный слой и residual соединения, чтобы добавить сети выразительности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights\n",
    "    \n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2\n",
    "    \n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "    \n",
    "    \n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = len(inp_lang_tokenizer.index_word) + 2\n",
    "target_vocab_size = len(targ_lang_tokenizer.index_word) + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "  \n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "  \n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 9.4029 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 9.3305 Accuracy 0.0110\n",
      "Epoch 1 Batch 100 Loss 9.2119 Accuracy 0.0235\n",
      "Epoch 1 Batch 150 Loss 9.0876 Accuracy 0.0280\n",
      "Epoch 1 Batch 200 Loss 8.9388 Accuracy 0.0303\n",
      "Epoch 1 Loss 8.7595 Accuracy 0.0316\n",
      "Epoch 2 Batch 0 Loss 7.7342 Accuracy 0.0370\n",
      "Epoch 2 Batch 50 Loss 7.4270 Accuracy 0.0562\n",
      "Epoch 2 Batch 100 Loss 7.1374 Accuracy 0.0617\n",
      "Epoch 2 Batch 150 Loss 6.8728 Accuracy 0.0635\n",
      "Epoch 2 Batch 200 Loss 6.6387 Accuracy 0.0644\n",
      "Epoch 2 Loss 6.4402 Accuracy 0.0656\n",
      "Epoch 3 Batch 0 Loss 5.5047 Accuracy 0.0706\n",
      "Epoch 3 Batch 50 Loss 5.3212 Accuracy 0.0856\n",
      "Epoch 3 Batch 100 Loss 5.2025 Accuracy 0.0915\n",
      "Epoch 3 Batch 150 Loss 5.1074 Accuracy 0.0952\n",
      "Epoch 3 Batch 200 Loss 5.0149 Accuracy 0.0984\n",
      "Epoch 3 Loss 4.9410 Accuracy 0.1005\n",
      "Epoch 4 Batch 0 Loss 4.8076 Accuracy 0.0949\n",
      "Epoch 4 Batch 50 Loss 4.4206 Accuracy 0.1126\n",
      "Epoch 4 Batch 100 Loss 4.4028 Accuracy 0.1122\n",
      "Epoch 4 Batch 150 Loss 4.3913 Accuracy 0.1122\n",
      "Epoch 4 Batch 200 Loss 4.3612 Accuracy 0.1133\n",
      "Epoch 4 Loss 4.3455 Accuracy 0.1136\n",
      "Epoch 5 Batch 0 Loss 4.1190 Accuracy 0.1204\n",
      "Epoch 5 Batch 50 Loss 4.0961 Accuracy 0.1183\n",
      "Epoch 5 Batch 100 Loss 4.0520 Accuracy 0.1199\n",
      "Epoch 5 Batch 150 Loss 4.0249 Accuracy 0.1207\n",
      "Epoch 5 Batch 200 Loss 4.0167 Accuracy 0.1211\n",
      "Epoch 5 Loss 4.0053 Accuracy 0.1216\n",
      "Epoch 6 Batch 0 Loss 3.8906 Accuracy 0.1146\n",
      "Epoch 6 Batch 50 Loss 3.7529 Accuracy 0.1272\n",
      "Epoch 6 Batch 100 Loss 3.7434 Accuracy 0.1275\n",
      "Epoch 6 Batch 150 Loss 3.7336 Accuracy 0.1279\n",
      "Epoch 6 Batch 200 Loss 3.7202 Accuracy 0.1282\n",
      "Epoch 6 Loss 3.7101 Accuracy 0.1287\n",
      "Epoch 7 Batch 0 Loss 3.6633 Accuracy 0.1314\n",
      "Epoch 7 Batch 50 Loss 3.4916 Accuracy 0.1340\n",
      "Epoch 7 Batch 100 Loss 3.4769 Accuracy 0.1334\n",
      "Epoch 7 Batch 150 Loss 3.4618 Accuracy 0.1340\n",
      "Epoch 7 Batch 200 Loss 3.4565 Accuracy 0.1343\n",
      "Epoch 7 Loss 3.4489 Accuracy 0.1346\n",
      "Epoch 8 Batch 0 Loss 3.1571 Accuracy 0.1522\n",
      "Epoch 8 Batch 50 Loss 3.1791 Accuracy 0.1404\n",
      "Epoch 8 Batch 100 Loss 3.2092 Accuracy 0.1399\n",
      "Epoch 8 Batch 150 Loss 3.2005 Accuracy 0.1407\n",
      "Epoch 8 Batch 200 Loss 3.1990 Accuracy 0.1408\n",
      "Epoch 8 Loss 3.1975 Accuracy 0.1410\n",
      "Epoch 9 Batch 0 Loss 3.0181 Accuracy 0.1481\n",
      "Epoch 9 Batch 50 Loss 2.9383 Accuracy 0.1467\n",
      "Epoch 9 Batch 100 Loss 2.9303 Accuracy 0.1471\n",
      "Epoch 9 Batch 150 Loss 2.9176 Accuracy 0.1476\n",
      "Epoch 9 Batch 200 Loss 2.9183 Accuracy 0.1483\n",
      "Epoch 9 Loss 2.9226 Accuracy 0.1486\n",
      "Epoch 10 Batch 0 Loss 2.6553 Accuracy 0.1557\n",
      "Epoch 10 Batch 50 Loss 2.6356 Accuracy 0.1573\n",
      "Epoch 10 Batch 100 Loss 2.6507 Accuracy 0.1562\n",
      "Epoch 10 Batch 150 Loss 2.6454 Accuracy 0.1567\n",
      "Epoch 10 Batch 200 Loss 2.6475 Accuracy 0.1564\n",
      "Epoch 10 Loss 2.6587 Accuracy 0.1562\n",
      "Epoch 11 Batch 0 Loss 2.3486 Accuracy 0.1615\n",
      "Epoch 11 Batch 50 Loss 2.3695 Accuracy 0.1635\n",
      "Epoch 11 Batch 100 Loss 2.3668 Accuracy 0.1642\n",
      "Epoch 11 Batch 150 Loss 2.3774 Accuracy 0.1641\n",
      "Epoch 11 Batch 200 Loss 2.3933 Accuracy 0.1637\n",
      "Epoch 11 Loss 2.4165 Accuracy 0.1634\n",
      "Epoch 12 Batch 0 Loss 1.9165 Accuracy 0.1655\n",
      "Epoch 12 Batch 50 Loss 2.1021 Accuracy 0.1732\n",
      "Epoch 12 Batch 100 Loss 2.1320 Accuracy 0.1719\n",
      "Epoch 12 Batch 150 Loss 2.1552 Accuracy 0.1713\n",
      "Epoch 12 Batch 200 Loss 2.1700 Accuracy 0.1711\n",
      "Epoch 12 Loss 2.1832 Accuracy 0.1710\n",
      "Epoch 13 Batch 0 Loss 1.7797 Accuracy 0.1748\n",
      "Epoch 13 Batch 50 Loss 1.8808 Accuracy 0.1810\n",
      "Epoch 13 Batch 100 Loss 1.9057 Accuracy 0.1800\n",
      "Epoch 13 Batch 150 Loss 1.9336 Accuracy 0.1794\n",
      "Epoch 13 Batch 200 Loss 1.9596 Accuracy 0.1783\n",
      "Epoch 13 Loss 1.9763 Accuracy 0.1779\n",
      "Epoch 14 Batch 0 Loss 1.5937 Accuracy 0.1887\n",
      "Epoch 14 Batch 50 Loss 1.6945 Accuracy 0.1874\n",
      "Epoch 14 Batch 100 Loss 1.7014 Accuracy 0.1866\n",
      "Epoch 14 Batch 150 Loss 1.7276 Accuracy 0.1859\n",
      "Epoch 14 Batch 200 Loss 1.7516 Accuracy 0.1851\n",
      "Epoch 14 Loss 1.7826 Accuracy 0.1847\n",
      "Epoch 15 Batch 0 Loss 1.5056 Accuracy 0.1927\n",
      "Epoch 15 Batch 50 Loss 1.4534 Accuracy 0.1964\n",
      "Epoch 15 Batch 100 Loss 1.4979 Accuracy 0.1954\n",
      "Epoch 15 Batch 150 Loss 1.5469 Accuracy 0.1929\n",
      "Epoch 15 Batch 200 Loss 1.5816 Accuracy 0.1918\n",
      "Epoch 15 Loss 1.6115 Accuracy 0.1909\n",
      "Epoch 16 Batch 0 Loss 1.3772 Accuracy 0.1991\n",
      "Epoch 16 Batch 50 Loss 1.3154 Accuracy 0.2040\n",
      "Epoch 16 Batch 100 Loss 1.3543 Accuracy 0.2004\n",
      "Epoch 16 Batch 150 Loss 1.3940 Accuracy 0.1992\n",
      "Epoch 16 Batch 200 Loss 1.4319 Accuracy 0.1974\n",
      "Epoch 16 Loss 1.4698 Accuracy 0.1962\n",
      "Epoch 17 Batch 0 Loss 1.1522 Accuracy 0.2043\n",
      "Epoch 17 Batch 50 Loss 1.1579 Accuracy 0.2108\n",
      "Epoch 17 Batch 100 Loss 1.2053 Accuracy 0.2078\n",
      "Epoch 17 Batch 150 Loss 1.2472 Accuracy 0.2054\n",
      "Epoch 17 Batch 200 Loss 1.2888 Accuracy 0.2036\n",
      "Epoch 17 Loss 1.3212 Accuracy 0.2023\n",
      "Epoch 18 Batch 0 Loss 0.9269 Accuracy 0.2448\n",
      "Epoch 18 Batch 50 Loss 0.9855 Accuracy 0.2188\n",
      "Epoch 18 Batch 100 Loss 1.0371 Accuracy 0.2167\n",
      "Epoch 18 Batch 150 Loss 1.0722 Accuracy 0.2143\n",
      "Epoch 18 Batch 200 Loss 1.1175 Accuracy 0.2116\n",
      "Epoch 18 Loss 1.1535 Accuracy 0.2095\n",
      "Epoch 19 Batch 0 Loss 0.9906 Accuracy 0.2419\n",
      "Epoch 19 Batch 50 Loss 0.8609 Accuracy 0.2266\n",
      "Epoch 19 Batch 100 Loss 0.9059 Accuracy 0.2233\n",
      "Epoch 19 Batch 150 Loss 0.9494 Accuracy 0.2205\n",
      "Epoch 19 Batch 200 Loss 0.9771 Accuracy 0.2185\n",
      "Epoch 19 Loss 1.0113 Accuracy 0.2167\n",
      "Epoch 20 Batch 0 Loss 0.7217 Accuracy 0.2326\n",
      "Epoch 20 Batch 50 Loss 0.7226 Accuracy 0.2344\n",
      "Epoch 20 Batch 100 Loss 0.7617 Accuracy 0.2318\n",
      "Epoch 20 Batch 150 Loss 0.8152 Accuracy 0.2279\n",
      "Epoch 20 Batch 200 Loss 0.8489 Accuracy 0.2257\n",
      "Epoch 20 Loss 0.8855 Accuracy 0.2240\n",
      "Epoch 21 Batch 0 Loss 0.6266 Accuracy 0.2321\n",
      "Epoch 21 Batch 50 Loss 0.6231 Accuracy 0.2390\n",
      "Epoch 21 Batch 100 Loss 0.6583 Accuracy 0.2367\n",
      "Epoch 21 Batch 150 Loss 0.6975 Accuracy 0.2335\n",
      "Epoch 21 Batch 200 Loss 0.7348 Accuracy 0.2315\n",
      "Epoch 21 Loss 0.7726 Accuracy 0.2296\n",
      "Epoch 22 Batch 0 Loss 0.6132 Accuracy 0.2465\n",
      "Epoch 22 Batch 50 Loss 0.5537 Accuracy 0.2469\n",
      "Epoch 22 Batch 100 Loss 0.5809 Accuracy 0.2437\n",
      "Epoch 22 Batch 150 Loss 0.6228 Accuracy 0.2394\n",
      "Epoch 22 Batch 200 Loss 0.6488 Accuracy 0.2371\n",
      "Epoch 22 Loss 0.6797 Accuracy 0.2348\n",
      "Epoch 23 Batch 0 Loss 0.4815 Accuracy 0.2546\n",
      "Epoch 23 Batch 50 Loss 0.4785 Accuracy 0.2490\n",
      "Epoch 23 Batch 100 Loss 0.5101 Accuracy 0.2462\n",
      "Epoch 23 Batch 150 Loss 0.5361 Accuracy 0.2443\n",
      "Epoch 23 Batch 200 Loss 0.5691 Accuracy 0.2415\n",
      "Epoch 23 Loss 0.6009 Accuracy 0.2397\n",
      "Epoch 24 Batch 0 Loss 0.3584 Accuracy 0.2494\n",
      "Epoch 24 Batch 50 Loss 0.4253 Accuracy 0.2487\n",
      "Epoch 24 Batch 100 Loss 0.4579 Accuracy 0.2485\n",
      "Epoch 24 Batch 150 Loss 0.4877 Accuracy 0.2465\n",
      "Epoch 24 Batch 200 Loss 0.5147 Accuracy 0.2452\n",
      "Epoch 24 Loss 0.5439 Accuracy 0.2432\n",
      "Epoch 25 Batch 0 Loss 0.3213 Accuracy 0.2674\n",
      "Epoch 25 Batch 50 Loss 0.3864 Accuracy 0.2548\n",
      "Epoch 25 Batch 100 Loss 0.4108 Accuracy 0.2520\n",
      "Epoch 25 Batch 150 Loss 0.4388 Accuracy 0.2495\n",
      "Epoch 25 Batch 200 Loss 0.4676 Accuracy 0.2479\n",
      "Epoch 25 Loss 0.4946 Accuracy 0.2463\n",
      "Epoch 26 Batch 0 Loss 0.3946 Accuracy 0.2378\n",
      "Epoch 26 Batch 50 Loss 0.3613 Accuracy 0.2533\n",
      "Epoch 26 Batch 100 Loss 0.3742 Accuracy 0.2545\n",
      "Epoch 26 Batch 150 Loss 0.4008 Accuracy 0.2524\n",
      "Epoch 26 Batch 200 Loss 0.4252 Accuracy 0.2503\n",
      "Epoch 26 Loss 0.4551 Accuracy 0.2489\n",
      "Epoch 27 Batch 0 Loss 0.2766 Accuracy 0.2627\n",
      "Epoch 27 Batch 50 Loss 0.3305 Accuracy 0.2565\n",
      "Epoch 27 Batch 100 Loss 0.3490 Accuracy 0.2545\n",
      "Epoch 27 Batch 150 Loss 0.3726 Accuracy 0.2531\n",
      "Epoch 27 Batch 200 Loss 0.3983 Accuracy 0.2519\n",
      "Epoch 27 Loss 0.4232 Accuracy 0.2509\n",
      "Epoch 28 Batch 0 Loss 0.2619 Accuracy 0.2708\n",
      "Epoch 28 Batch 50 Loss 0.2974 Accuracy 0.2581\n",
      "Epoch 28 Batch 100 Loss 0.3166 Accuracy 0.2590\n",
      "Epoch 28 Batch 150 Loss 0.3432 Accuracy 0.2567\n",
      "Epoch 28 Batch 200 Loss 0.3671 Accuracy 0.2550\n",
      "Epoch 28 Loss 0.3914 Accuracy 0.2534\n",
      "Epoch 29 Batch 0 Loss 0.2862 Accuracy 0.2598\n",
      "Epoch 29 Batch 50 Loss 0.2839 Accuracy 0.2599\n",
      "Epoch 29 Batch 100 Loss 0.3009 Accuracy 0.2591\n",
      "Epoch 29 Batch 150 Loss 0.3220 Accuracy 0.2578\n",
      "Epoch 29 Batch 200 Loss 0.3452 Accuracy 0.2566\n",
      "Epoch 29 Loss 0.3679 Accuracy 0.2552\n",
      "Epoch 30 Batch 0 Loss 0.2296 Accuracy 0.2755\n",
      "Epoch 30 Batch 50 Loss 0.2705 Accuracy 0.2604\n",
      "Epoch 30 Batch 100 Loss 0.2900 Accuracy 0.2598\n",
      "Epoch 30 Batch 150 Loss 0.3062 Accuracy 0.2587\n",
      "Epoch 30 Batch 200 Loss 0.3276 Accuracy 0.2578\n",
      "Epoch 30 Loss 0.3484 Accuracy 0.2566\n",
      "Epoch 31 Batch 0 Loss 0.2337 Accuracy 0.2708\n",
      "Epoch 31 Batch 50 Loss 0.2442 Accuracy 0.2628\n",
      "Epoch 31 Batch 100 Loss 0.2635 Accuracy 0.2624\n",
      "Epoch 31 Batch 150 Loss 0.2834 Accuracy 0.2617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 200 Loss 0.3050 Accuracy 0.2596\n",
      "Epoch 31 Loss 0.3276 Accuracy 0.2580\n",
      "Epoch 32 Batch 0 Loss 0.1836 Accuracy 0.2714\n",
      "Epoch 32 Batch 50 Loss 0.2349 Accuracy 0.2668\n",
      "Epoch 32 Batch 100 Loss 0.2459 Accuracy 0.2650\n",
      "Epoch 32 Batch 150 Loss 0.2642 Accuracy 0.2630\n",
      "Epoch 32 Batch 200 Loss 0.2872 Accuracy 0.2610\n",
      "Epoch 32 Loss 0.3096 Accuracy 0.2595\n",
      "Epoch 33 Batch 0 Loss 0.1886 Accuracy 0.2755\n",
      "Epoch 33 Batch 50 Loss 0.2287 Accuracy 0.2643\n",
      "Epoch 33 Batch 100 Loss 0.2429 Accuracy 0.2635\n",
      "Epoch 33 Batch 150 Loss 0.2614 Accuracy 0.2619\n",
      "Epoch 33 Batch 200 Loss 0.2805 Accuracy 0.2610\n",
      "Epoch 33 Loss 0.2992 Accuracy 0.2603\n",
      "Epoch 34 Batch 0 Loss 0.2190 Accuracy 0.2587\n",
      "Epoch 34 Batch 50 Loss 0.2236 Accuracy 0.2657\n",
      "Epoch 34 Batch 100 Loss 0.2305 Accuracy 0.2656\n",
      "Epoch 34 Batch 150 Loss 0.2471 Accuracy 0.2637\n",
      "Epoch 34 Batch 200 Loss 0.2633 Accuracy 0.2627\n",
      "Epoch 34 Loss 0.2820 Accuracy 0.2615\n",
      "Epoch 35 Batch 0 Loss 0.1647 Accuracy 0.2969\n",
      "Epoch 35 Batch 50 Loss 0.2069 Accuracy 0.2671\n",
      "Epoch 35 Batch 100 Loss 0.2212 Accuracy 0.2660\n",
      "Epoch 35 Batch 150 Loss 0.2372 Accuracy 0.2652\n",
      "Epoch 35 Batch 200 Loss 0.2543 Accuracy 0.2633\n",
      "Epoch 35 Loss 0.2711 Accuracy 0.2625\n",
      "Epoch 36 Batch 0 Loss 0.1820 Accuracy 0.2558\n",
      "Epoch 36 Batch 50 Loss 0.1959 Accuracy 0.2677\n",
      "Epoch 36 Batch 100 Loss 0.2121 Accuracy 0.2677\n",
      "Epoch 36 Batch 150 Loss 0.2259 Accuracy 0.2664\n",
      "Epoch 36 Batch 200 Loss 0.2425 Accuracy 0.2647\n",
      "Epoch 36 Loss 0.2614 Accuracy 0.2635\n",
      "Epoch 37 Batch 0 Loss 0.1721 Accuracy 0.2558\n",
      "Epoch 37 Batch 50 Loss 0.1941 Accuracy 0.2673\n",
      "Epoch 37 Batch 100 Loss 0.2038 Accuracy 0.2671\n",
      "Epoch 37 Batch 150 Loss 0.2190 Accuracy 0.2672\n",
      "Epoch 37 Batch 200 Loss 0.2351 Accuracy 0.2653\n",
      "Epoch 37 Loss 0.2534 Accuracy 0.2642\n",
      "Epoch 38 Batch 0 Loss 0.1822 Accuracy 0.2708\n",
      "Epoch 38 Batch 50 Loss 0.1794 Accuracy 0.2697\n",
      "Epoch 38 Batch 100 Loss 0.1932 Accuracy 0.2675\n",
      "Epoch 38 Batch 150 Loss 0.2068 Accuracy 0.2669\n",
      "Epoch 38 Batch 200 Loss 0.2201 Accuracy 0.2661\n",
      "Epoch 38 Loss 0.2416 Accuracy 0.2650\n",
      "Epoch 39 Batch 0 Loss 0.1283 Accuracy 0.2488\n",
      "Epoch 39 Batch 50 Loss 0.1732 Accuracy 0.2698\n",
      "Epoch 39 Batch 100 Loss 0.1787 Accuracy 0.2695\n",
      "Epoch 39 Batch 150 Loss 0.1937 Accuracy 0.2674\n",
      "Epoch 39 Batch 200 Loss 0.2116 Accuracy 0.2669\n",
      "Epoch 39 Loss 0.2310 Accuracy 0.2662\n",
      "Epoch 40 Batch 0 Loss 0.1954 Accuracy 0.2650\n",
      "Epoch 40 Batch 50 Loss 0.1653 Accuracy 0.2711\n",
      "Epoch 40 Batch 100 Loss 0.1765 Accuracy 0.2706\n",
      "Epoch 40 Batch 150 Loss 0.1890 Accuracy 0.2695\n",
      "Epoch 40 Batch 200 Loss 0.2044 Accuracy 0.2680\n",
      "Epoch 40 Loss 0.2256 Accuracy 0.2665\n",
      "Epoch 41 Batch 0 Loss 0.1425 Accuracy 0.2616\n",
      "Epoch 41 Batch 50 Loss 0.1573 Accuracy 0.2708\n",
      "Epoch 41 Batch 100 Loss 0.1687 Accuracy 0.2699\n",
      "Epoch 41 Batch 150 Loss 0.1852 Accuracy 0.2683\n",
      "Epoch 41 Batch 200 Loss 0.1999 Accuracy 0.2680\n",
      "Epoch 41 Loss 0.2185 Accuracy 0.2671\n",
      "Epoch 42 Batch 0 Loss 0.1067 Accuracy 0.2865\n",
      "Epoch 42 Batch 50 Loss 0.1596 Accuracy 0.2722\n",
      "Epoch 42 Batch 100 Loss 0.1693 Accuracy 0.2707\n",
      "Epoch 42 Batch 150 Loss 0.1819 Accuracy 0.2708\n",
      "Epoch 42 Batch 200 Loss 0.1952 Accuracy 0.2691\n",
      "Epoch 42 Loss 0.2112 Accuracy 0.2677\n",
      "Epoch 43 Batch 0 Loss 0.1157 Accuracy 0.2824\n",
      "Epoch 43 Batch 50 Loss 0.1489 Accuracy 0.2706\n",
      "Epoch 43 Batch 100 Loss 0.1588 Accuracy 0.2713\n",
      "Epoch 43 Batch 150 Loss 0.1695 Accuracy 0.2708\n",
      "Epoch 43 Batch 200 Loss 0.1852 Accuracy 0.2697\n",
      "Epoch 43 Loss 0.2046 Accuracy 0.2685\n",
      "Epoch 44 Batch 0 Loss 0.1451 Accuracy 0.2639\n",
      "Epoch 44 Batch 50 Loss 0.1487 Accuracy 0.2721\n",
      "Epoch 44 Batch 100 Loss 0.1576 Accuracy 0.2718\n",
      "Epoch 44 Batch 150 Loss 0.1695 Accuracy 0.2711\n",
      "Epoch 44 Batch 200 Loss 0.1847 Accuracy 0.2697\n",
      "Epoch 44 Loss 0.2004 Accuracy 0.2689\n",
      "Epoch 45 Batch 0 Loss 0.1600 Accuracy 0.2622\n",
      "Epoch 45 Batch 50 Loss 0.1449 Accuracy 0.2725\n",
      "Epoch 45 Batch 100 Loss 0.1530 Accuracy 0.2722\n",
      "Epoch 45 Batch 150 Loss 0.1617 Accuracy 0.2715\n",
      "Epoch 45 Batch 200 Loss 0.1755 Accuracy 0.2702\n",
      "Epoch 45 Loss 0.1935 Accuracy 0.2694\n",
      "Epoch 46 Batch 0 Loss 0.1179 Accuracy 0.2760\n",
      "Epoch 46 Batch 50 Loss 0.1375 Accuracy 0.2743\n",
      "Epoch 46 Batch 100 Loss 0.1419 Accuracy 0.2730\n",
      "Epoch 46 Batch 150 Loss 0.1562 Accuracy 0.2722\n",
      "Epoch 46 Batch 200 Loss 0.1710 Accuracy 0.2712\n",
      "Epoch 46 Loss 0.1912 Accuracy 0.2698\n",
      "Epoch 47 Batch 0 Loss 0.1199 Accuracy 0.2801\n",
      "Epoch 47 Batch 50 Loss 0.1272 Accuracy 0.2729\n",
      "Epoch 47 Batch 100 Loss 0.1427 Accuracy 0.2718\n",
      "Epoch 47 Batch 150 Loss 0.1545 Accuracy 0.2717\n",
      "Epoch 47 Batch 200 Loss 0.1695 Accuracy 0.2715\n",
      "Epoch 47 Loss 0.1876 Accuracy 0.2701\n",
      "Epoch 48 Batch 0 Loss 0.1328 Accuracy 0.2812\n",
      "Epoch 48 Batch 50 Loss 0.1288 Accuracy 0.2749\n",
      "Epoch 48 Batch 100 Loss 0.1397 Accuracy 0.2737\n",
      "Epoch 48 Batch 150 Loss 0.1522 Accuracy 0.2725\n",
      "Epoch 48 Batch 200 Loss 0.1688 Accuracy 0.2715\n",
      "Epoch 48 Loss 0.1846 Accuracy 0.2706\n",
      "Epoch 49 Batch 0 Loss 0.1087 Accuracy 0.2755\n",
      "Epoch 49 Batch 50 Loss 0.1257 Accuracy 0.2739\n",
      "Epoch 49 Batch 100 Loss 0.1379 Accuracy 0.2743\n",
      "Epoch 49 Batch 150 Loss 0.1487 Accuracy 0.2740\n",
      "Epoch 49 Batch 200 Loss 0.1622 Accuracy 0.2727\n",
      "Epoch 49 Loss 0.1792 Accuracy 0.2710\n",
      "Epoch 50 Batch 0 Loss 0.0903 Accuracy 0.2865\n",
      "Epoch 50 Batch 50 Loss 0.1228 Accuracy 0.2752\n",
      "Epoch 50 Batch 100 Loss 0.1327 Accuracy 0.2741\n",
      "Epoch 50 Batch 150 Loss 0.1442 Accuracy 0.2731\n",
      "Epoch 50 Batch 200 Loss 0.1610 Accuracy 0.2718\n",
      "Epoch 50 Loss 0.1792 Accuracy 0.2708\n",
      "Epoch 51 Batch 0 Loss 0.1474 Accuracy 0.2760\n",
      "Epoch 51 Batch 50 Loss 0.1168 Accuracy 0.2747\n",
      "Epoch 51 Batch 100 Loss 0.1283 Accuracy 0.2740\n",
      "Epoch 51 Batch 150 Loss 0.1416 Accuracy 0.2732\n",
      "Epoch 51 Batch 200 Loss 0.1570 Accuracy 0.2729\n",
      "Epoch 51 Loss 0.1763 Accuracy 0.2716\n",
      "Epoch 52 Batch 0 Loss 0.1532 Accuracy 0.2847\n",
      "Epoch 52 Batch 50 Loss 0.1210 Accuracy 0.2772\n",
      "Epoch 52 Batch 100 Loss 0.1286 Accuracy 0.2750\n",
      "Epoch 52 Batch 150 Loss 0.1378 Accuracy 0.2741\n",
      "Epoch 52 Batch 200 Loss 0.1530 Accuracy 0.2736\n",
      "Epoch 52 Loss 0.1708 Accuracy 0.2720\n",
      "Epoch 53 Batch 0 Loss 0.1114 Accuracy 0.2801\n",
      "Epoch 53 Batch 50 Loss 0.1158 Accuracy 0.2743\n",
      "Epoch 53 Batch 100 Loss 0.1275 Accuracy 0.2754\n",
      "Epoch 53 Batch 150 Loss 0.1394 Accuracy 0.2741\n",
      "Epoch 53 Batch 200 Loss 0.1533 Accuracy 0.2730\n",
      "Epoch 53 Loss 0.1711 Accuracy 0.2721\n",
      "Epoch 54 Batch 0 Loss 0.1149 Accuracy 0.2755\n",
      "Epoch 54 Batch 50 Loss 0.1137 Accuracy 0.2738\n",
      "Epoch 54 Batch 100 Loss 0.1218 Accuracy 0.2749\n",
      "Epoch 54 Batch 150 Loss 0.1323 Accuracy 0.2746\n",
      "Epoch 54 Batch 200 Loss 0.1471 Accuracy 0.2735\n",
      "Epoch 54 Loss 0.1662 Accuracy 0.2726\n",
      "Epoch 55 Batch 0 Loss 0.0969 Accuracy 0.2564\n",
      "Epoch 55 Batch 50 Loss 0.1075 Accuracy 0.2771\n",
      "Epoch 55 Batch 100 Loss 0.1191 Accuracy 0.2769\n",
      "Epoch 55 Batch 150 Loss 0.1321 Accuracy 0.2748\n",
      "Epoch 55 Batch 200 Loss 0.1483 Accuracy 0.2735\n",
      "Epoch 55 Loss 0.1650 Accuracy 0.2726\n",
      "Epoch 56 Batch 0 Loss 0.1093 Accuracy 0.2986\n",
      "Epoch 56 Batch 50 Loss 0.1060 Accuracy 0.2769\n",
      "Epoch 56 Batch 100 Loss 0.1164 Accuracy 0.2747\n",
      "Epoch 56 Batch 150 Loss 0.1255 Accuracy 0.2751\n",
      "Epoch 56 Batch 200 Loss 0.1405 Accuracy 0.2738\n",
      "Epoch 56 Loss 0.1596 Accuracy 0.2730\n",
      "Epoch 57 Batch 0 Loss 0.0663 Accuracy 0.2691\n",
      "Epoch 57 Batch 50 Loss 0.1017 Accuracy 0.2772\n",
      "Epoch 57 Batch 100 Loss 0.1153 Accuracy 0.2762\n",
      "Epoch 57 Batch 150 Loss 0.1265 Accuracy 0.2760\n",
      "Epoch 57 Batch 200 Loss 0.1427 Accuracy 0.2743\n",
      "Epoch 57 Loss 0.1618 Accuracy 0.2731\n",
      "Epoch 58 Batch 0 Loss 0.0752 Accuracy 0.2668\n",
      "Epoch 58 Batch 50 Loss 0.1062 Accuracy 0.2792\n",
      "Epoch 58 Batch 100 Loss 0.1159 Accuracy 0.2761\n",
      "Epoch 58 Batch 150 Loss 0.1275 Accuracy 0.2758\n",
      "Epoch 58 Batch 200 Loss 0.1389 Accuracy 0.2748\n",
      "Epoch 58 Loss 0.1586 Accuracy 0.2734\n",
      "Epoch 59 Batch 0 Loss 0.1648 Accuracy 0.2697\n",
      "Epoch 59 Batch 50 Loss 0.1081 Accuracy 0.2787\n",
      "Epoch 59 Batch 100 Loss 0.1133 Accuracy 0.2771\n",
      "Epoch 59 Batch 150 Loss 0.1250 Accuracy 0.2759\n",
      "Epoch 59 Batch 200 Loss 0.1401 Accuracy 0.2744\n",
      "Epoch 59 Loss 0.1582 Accuracy 0.2734\n",
      "Epoch 60 Batch 0 Loss 0.0961 Accuracy 0.2946\n",
      "Epoch 60 Batch 50 Loss 0.0989 Accuracy 0.2785\n",
      "Epoch 60 Batch 100 Loss 0.1088 Accuracy 0.2770\n",
      "Epoch 60 Batch 150 Loss 0.1224 Accuracy 0.2761\n",
      "Epoch 60 Batch 200 Loss 0.1367 Accuracy 0.2750\n",
      "Epoch 60 Loss 0.1554 Accuracy 0.2736\n",
      "Epoch 61 Batch 0 Loss 0.1296 Accuracy 0.2807\n",
      "Epoch 61 Batch 50 Loss 0.1061 Accuracy 0.2774\n",
      "Epoch 61 Batch 100 Loss 0.1124 Accuracy 0.2765\n",
      "Epoch 61 Batch 150 Loss 0.1241 Accuracy 0.2758\n",
      "Epoch 61 Batch 200 Loss 0.1365 Accuracy 0.2750\n",
      "Epoch 61 Loss 0.1546 Accuracy 0.2740\n",
      "Epoch 62 Batch 0 Loss 0.0998 Accuracy 0.2760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Batch 50 Loss 0.0980 Accuracy 0.2785\n",
      "Epoch 62 Batch 100 Loss 0.1043 Accuracy 0.2772\n",
      "Epoch 62 Batch 150 Loss 0.1167 Accuracy 0.2773\n",
      "Epoch 62 Batch 200 Loss 0.1312 Accuracy 0.2756\n",
      "Epoch 62 Loss 0.1511 Accuracy 0.2742\n",
      "Epoch 63 Batch 0 Loss 0.1030 Accuracy 0.2940\n",
      "Epoch 63 Batch 50 Loss 0.1013 Accuracy 0.2767\n",
      "Epoch 63 Batch 100 Loss 0.1085 Accuracy 0.2748\n",
      "Epoch 63 Batch 150 Loss 0.1202 Accuracy 0.2751\n",
      "Epoch 63 Batch 200 Loss 0.1352 Accuracy 0.2753\n",
      "Epoch 63 Loss 0.1527 Accuracy 0.2743\n",
      "Epoch 64 Batch 0 Loss 0.0886 Accuracy 0.2760\n",
      "Epoch 64 Batch 50 Loss 0.0964 Accuracy 0.2782\n",
      "Epoch 64 Batch 100 Loss 0.1024 Accuracy 0.2768\n",
      "Epoch 64 Batch 150 Loss 0.1133 Accuracy 0.2766\n",
      "Epoch 64 Batch 200 Loss 0.1290 Accuracy 0.2753\n",
      "Epoch 64 Loss 0.1480 Accuracy 0.2743\n",
      "Epoch 65 Batch 0 Loss 0.0878 Accuracy 0.2899\n",
      "Epoch 65 Batch 50 Loss 0.0958 Accuracy 0.2784\n",
      "Epoch 65 Batch 100 Loss 0.1036 Accuracy 0.2783\n",
      "Epoch 65 Batch 150 Loss 0.1154 Accuracy 0.2770\n",
      "Epoch 65 Batch 200 Loss 0.1322 Accuracy 0.2758\n",
      "Epoch 65 Loss 0.1525 Accuracy 0.2743\n",
      "Epoch 66 Batch 0 Loss 0.0966 Accuracy 0.2876\n",
      "Epoch 66 Batch 50 Loss 0.0961 Accuracy 0.2774\n",
      "Epoch 66 Batch 100 Loss 0.1055 Accuracy 0.2779\n",
      "Epoch 66 Batch 150 Loss 0.1166 Accuracy 0.2766\n",
      "Epoch 66 Batch 200 Loss 0.1305 Accuracy 0.2759\n",
      "Epoch 66 Loss 0.1505 Accuracy 0.2744\n",
      "Epoch 67 Batch 0 Loss 0.0691 Accuracy 0.2749\n",
      "Epoch 67 Batch 50 Loss 0.0952 Accuracy 0.2777\n",
      "Epoch 67 Batch 100 Loss 0.1033 Accuracy 0.2767\n",
      "Epoch 67 Batch 150 Loss 0.1140 Accuracy 0.2761\n",
      "Epoch 67 Batch 200 Loss 0.1295 Accuracy 0.2759\n",
      "Epoch 67 Loss 0.1460 Accuracy 0.2747\n",
      "Epoch 68 Batch 0 Loss 0.0943 Accuracy 0.2870\n",
      "Epoch 68 Batch 50 Loss 0.0982 Accuracy 0.2766\n",
      "Epoch 68 Batch 100 Loss 0.1019 Accuracy 0.2763\n",
      "Epoch 68 Batch 150 Loss 0.1152 Accuracy 0.2762\n",
      "Epoch 68 Batch 200 Loss 0.1292 Accuracy 0.2754\n",
      "Epoch 68 Loss 0.1463 Accuracy 0.2748\n",
      "Epoch 69 Batch 0 Loss 0.0937 Accuracy 0.2749\n",
      "Epoch 69 Batch 50 Loss 0.0886 Accuracy 0.2771\n",
      "Epoch 69 Batch 100 Loss 0.0991 Accuracy 0.2772\n",
      "Epoch 69 Batch 150 Loss 0.1081 Accuracy 0.2773\n",
      "Epoch 69 Batch 200 Loss 0.1219 Accuracy 0.2765\n",
      "Epoch 69 Loss 0.1413 Accuracy 0.2752\n",
      "Epoch 70 Batch 0 Loss 0.0752 Accuracy 0.2836\n",
      "Epoch 70 Batch 50 Loss 0.0873 Accuracy 0.2806\n",
      "Epoch 70 Batch 100 Loss 0.0976 Accuracy 0.2791\n",
      "Epoch 70 Batch 150 Loss 0.1097 Accuracy 0.2765\n",
      "Epoch 70 Batch 200 Loss 0.1253 Accuracy 0.2755\n",
      "Epoch 70 Loss 0.1443 Accuracy 0.2750\n",
      "Epoch 71 Batch 0 Loss 0.0749 Accuracy 0.2824\n",
      "Epoch 71 Batch 50 Loss 0.0937 Accuracy 0.2786\n",
      "Epoch 71 Batch 100 Loss 0.0989 Accuracy 0.2775\n",
      "Epoch 71 Batch 150 Loss 0.1108 Accuracy 0.2772\n",
      "Epoch 71 Batch 200 Loss 0.1255 Accuracy 0.2766\n",
      "Epoch 71 Loss 0.1443 Accuracy 0.2751\n",
      "Epoch 72 Batch 0 Loss 0.1127 Accuracy 0.2679\n",
      "Epoch 72 Batch 50 Loss 0.0860 Accuracy 0.2797\n",
      "Epoch 72 Batch 100 Loss 0.0959 Accuracy 0.2783\n",
      "Epoch 72 Batch 150 Loss 0.1075 Accuracy 0.2774\n",
      "Epoch 72 Batch 200 Loss 0.1226 Accuracy 0.2761\n",
      "Epoch 72 Loss 0.1412 Accuracy 0.2755\n",
      "Epoch 73 Batch 0 Loss 0.0785 Accuracy 0.2720\n",
      "Epoch 73 Batch 50 Loss 0.0880 Accuracy 0.2780\n",
      "Epoch 73 Batch 100 Loss 0.0953 Accuracy 0.2794\n",
      "Epoch 73 Batch 150 Loss 0.1092 Accuracy 0.2778\n",
      "Epoch 73 Batch 200 Loss 0.1227 Accuracy 0.2768\n",
      "Epoch 73 Loss 0.1395 Accuracy 0.2756\n",
      "Epoch 74 Batch 0 Loss 0.0709 Accuracy 0.2795\n",
      "Epoch 74 Batch 50 Loss 0.0842 Accuracy 0.2775\n",
      "Epoch 74 Batch 100 Loss 0.0955 Accuracy 0.2775\n",
      "Epoch 74 Batch 150 Loss 0.1063 Accuracy 0.2768\n",
      "Epoch 74 Batch 200 Loss 0.1214 Accuracy 0.2767\n",
      "Epoch 74 Loss 0.1400 Accuracy 0.2756\n",
      "Epoch 75 Batch 0 Loss 0.1185 Accuracy 0.2812\n",
      "Epoch 75 Batch 50 Loss 0.0915 Accuracy 0.2775\n",
      "Epoch 75 Batch 100 Loss 0.0975 Accuracy 0.2778\n",
      "Epoch 75 Batch 150 Loss 0.1050 Accuracy 0.2776\n",
      "Epoch 75 Batch 200 Loss 0.1193 Accuracy 0.2768\n",
      "Epoch 75 Loss 0.1394 Accuracy 0.2756\n",
      "Epoch 76 Batch 0 Loss 0.0679 Accuracy 0.2824\n",
      "Epoch 76 Batch 50 Loss 0.0822 Accuracy 0.2777\n",
      "Epoch 76 Batch 100 Loss 0.0954 Accuracy 0.2773\n",
      "Epoch 76 Batch 150 Loss 0.1074 Accuracy 0.2770\n",
      "Epoch 76 Batch 200 Loss 0.1216 Accuracy 0.2766\n",
      "Epoch 76 Loss 0.1415 Accuracy 0.2755\n",
      "Epoch 77 Batch 0 Loss 0.1032 Accuracy 0.2656\n",
      "Epoch 77 Batch 50 Loss 0.0859 Accuracy 0.2790\n",
      "Epoch 77 Batch 100 Loss 0.0923 Accuracy 0.2786\n",
      "Epoch 77 Batch 150 Loss 0.1020 Accuracy 0.2779\n",
      "Epoch 77 Batch 200 Loss 0.1173 Accuracy 0.2770\n",
      "Epoch 77 Loss 0.1361 Accuracy 0.2758\n",
      "Epoch 78 Batch 0 Loss 0.0587 Accuracy 0.2789\n",
      "Epoch 78 Batch 50 Loss 0.0840 Accuracy 0.2785\n",
      "Epoch 78 Batch 100 Loss 0.0954 Accuracy 0.2781\n",
      "Epoch 78 Batch 150 Loss 0.1064 Accuracy 0.2764\n",
      "Epoch 78 Batch 200 Loss 0.1209 Accuracy 0.2762\n",
      "Epoch 78 Loss 0.1394 Accuracy 0.2757\n",
      "Epoch 79 Batch 0 Loss 0.0640 Accuracy 0.2801\n",
      "Epoch 79 Batch 50 Loss 0.0841 Accuracy 0.2796\n",
      "Epoch 79 Batch 100 Loss 0.0903 Accuracy 0.2793\n",
      "Epoch 79 Batch 150 Loss 0.1009 Accuracy 0.2787\n",
      "Epoch 79 Batch 200 Loss 0.1158 Accuracy 0.2769\n",
      "Epoch 79 Loss 0.1364 Accuracy 0.2760\n",
      "Epoch 80 Batch 0 Loss 0.0548 Accuracy 0.2876\n",
      "Epoch 80 Batch 50 Loss 0.0840 Accuracy 0.2805\n",
      "Epoch 80 Batch 100 Loss 0.0901 Accuracy 0.2791\n",
      "Epoch 80 Batch 150 Loss 0.1048 Accuracy 0.2773\n",
      "Epoch 80 Batch 200 Loss 0.1202 Accuracy 0.2757\n",
      "Epoch 80 Loss 0.1398 Accuracy 0.2758\n",
      "Epoch 81 Batch 0 Loss 0.0834 Accuracy 0.2720\n",
      "Epoch 81 Batch 50 Loss 0.0817 Accuracy 0.2802\n",
      "Epoch 81 Batch 100 Loss 0.0890 Accuracy 0.2786\n",
      "Epoch 81 Batch 150 Loss 0.1015 Accuracy 0.2783\n",
      "Epoch 81 Batch 200 Loss 0.1160 Accuracy 0.2766\n",
      "Epoch 81 Loss 0.1333 Accuracy 0.2763\n",
      "Epoch 82 Batch 0 Loss 0.0661 Accuracy 0.3079\n",
      "Epoch 82 Batch 50 Loss 0.0800 Accuracy 0.2779\n",
      "Epoch 82 Batch 100 Loss 0.0864 Accuracy 0.2791\n",
      "Epoch 82 Batch 150 Loss 0.0972 Accuracy 0.2789\n",
      "Epoch 82 Batch 200 Loss 0.1134 Accuracy 0.2775\n",
      "Epoch 82 Loss 0.1333 Accuracy 0.2763\n",
      "Epoch 83 Batch 0 Loss 0.0574 Accuracy 0.2766\n",
      "Epoch 83 Batch 50 Loss 0.0762 Accuracy 0.2806\n",
      "Epoch 83 Batch 100 Loss 0.0861 Accuracy 0.2801\n",
      "Epoch 83 Batch 150 Loss 0.0993 Accuracy 0.2781\n",
      "Epoch 83 Batch 200 Loss 0.1159 Accuracy 0.2773\n",
      "Epoch 83 Loss 0.1347 Accuracy 0.2763\n",
      "Epoch 84 Batch 0 Loss 0.0853 Accuracy 0.2946\n",
      "Epoch 84 Batch 50 Loss 0.0810 Accuracy 0.2785\n",
      "Epoch 84 Batch 100 Loss 0.0897 Accuracy 0.2798\n",
      "Epoch 84 Batch 150 Loss 0.0996 Accuracy 0.2790\n",
      "Epoch 84 Batch 200 Loss 0.1166 Accuracy 0.2773\n",
      "Epoch 84 Loss 0.1356 Accuracy 0.2763\n",
      "Epoch 85 Batch 0 Loss 0.0816 Accuracy 0.2506\n",
      "Epoch 85 Batch 50 Loss 0.0836 Accuracy 0.2790\n",
      "Epoch 85 Batch 100 Loss 0.0893 Accuracy 0.2783\n",
      "Epoch 85 Batch 150 Loss 0.0999 Accuracy 0.2771\n",
      "Epoch 85 Batch 200 Loss 0.1147 Accuracy 0.2765\n",
      "Epoch 85 Loss 0.1344 Accuracy 0.2764\n",
      "Epoch 86 Batch 0 Loss 0.0746 Accuracy 0.2784\n",
      "Epoch 86 Batch 50 Loss 0.0799 Accuracy 0.2793\n",
      "Epoch 86 Batch 100 Loss 0.0892 Accuracy 0.2793\n",
      "Epoch 86 Batch 150 Loss 0.1007 Accuracy 0.2782\n",
      "Epoch 86 Batch 200 Loss 0.1151 Accuracy 0.2775\n",
      "Epoch 86 Loss 0.1329 Accuracy 0.2763\n",
      "Epoch 87 Batch 0 Loss 0.0801 Accuracy 0.2865\n",
      "Epoch 87 Batch 50 Loss 0.0799 Accuracy 0.2799\n",
      "Epoch 87 Batch 100 Loss 0.0905 Accuracy 0.2794\n",
      "Epoch 87 Batch 150 Loss 0.1014 Accuracy 0.2777\n",
      "Epoch 87 Batch 200 Loss 0.1156 Accuracy 0.2775\n",
      "Epoch 87 Loss 0.1339 Accuracy 0.2764\n",
      "Epoch 88 Batch 0 Loss 0.0810 Accuracy 0.2946\n",
      "Epoch 88 Batch 50 Loss 0.0808 Accuracy 0.2761\n",
      "Epoch 88 Batch 100 Loss 0.0870 Accuracy 0.2772\n",
      "Epoch 88 Batch 150 Loss 0.0983 Accuracy 0.2775\n",
      "Epoch 88 Batch 200 Loss 0.1130 Accuracy 0.2773\n",
      "Epoch 88 Loss 0.1332 Accuracy 0.2764\n",
      "Epoch 89 Batch 0 Loss 0.0750 Accuracy 0.2627\n",
      "Epoch 89 Batch 50 Loss 0.0783 Accuracy 0.2787\n",
      "Epoch 89 Batch 100 Loss 0.0866 Accuracy 0.2792\n",
      "Epoch 89 Batch 150 Loss 0.0972 Accuracy 0.2789\n",
      "Epoch 89 Batch 200 Loss 0.1128 Accuracy 0.2778\n",
      "Epoch 89 Loss 0.1325 Accuracy 0.2766\n",
      "Epoch 90 Batch 0 Loss 0.0729 Accuracy 0.2818\n",
      "Epoch 90 Batch 50 Loss 0.0840 Accuracy 0.2796\n",
      "Epoch 90 Batch 100 Loss 0.0934 Accuracy 0.2777\n",
      "Epoch 90 Batch 150 Loss 0.1001 Accuracy 0.2786\n",
      "Epoch 90 Batch 200 Loss 0.1161 Accuracy 0.2778\n",
      "Epoch 90 Loss 0.1359 Accuracy 0.2765\n",
      "Epoch 91 Batch 0 Loss 0.0743 Accuracy 0.2737\n",
      "Epoch 91 Batch 50 Loss 0.0848 Accuracy 0.2808\n",
      "Epoch 91 Batch 100 Loss 0.0899 Accuracy 0.2784\n",
      "Epoch 91 Batch 150 Loss 0.0997 Accuracy 0.2774\n",
      "Epoch 91 Batch 200 Loss 0.1161 Accuracy 0.2769\n",
      "Epoch 91 Loss 0.1352 Accuracy 0.2766\n",
      "Epoch 92 Batch 0 Loss 0.0503 Accuracy 0.2772\n",
      "Epoch 92 Batch 50 Loss 0.0831 Accuracy 0.2806\n",
      "Epoch 92 Batch 100 Loss 0.0875 Accuracy 0.2805\n",
      "Epoch 92 Batch 150 Loss 0.0983 Accuracy 0.2796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Batch 200 Loss 0.1130 Accuracy 0.2783\n",
      "Epoch 92 Loss 0.1334 Accuracy 0.2767\n",
      "Epoch 93 Batch 0 Loss 0.0718 Accuracy 0.2882\n",
      "Epoch 93 Batch 50 Loss 0.0713 Accuracy 0.2816\n",
      "Epoch 93 Batch 100 Loss 0.0822 Accuracy 0.2804\n",
      "Epoch 93 Batch 150 Loss 0.0943 Accuracy 0.2792\n",
      "Epoch 93 Batch 200 Loss 0.1101 Accuracy 0.2782\n",
      "Epoch 93 Loss 0.1295 Accuracy 0.2768\n",
      "Epoch 94 Batch 0 Loss 0.0624 Accuracy 0.2876\n",
      "Epoch 94 Batch 50 Loss 0.0787 Accuracy 0.2785\n",
      "Epoch 94 Batch 100 Loss 0.0870 Accuracy 0.2785\n",
      "Epoch 94 Batch 150 Loss 0.0987 Accuracy 0.2776\n",
      "Epoch 94 Batch 200 Loss 0.1126 Accuracy 0.2775\n",
      "Epoch 94 Loss 0.1310 Accuracy 0.2767\n",
      "Epoch 95 Batch 0 Loss 0.0592 Accuracy 0.2760\n",
      "Epoch 95 Batch 50 Loss 0.0777 Accuracy 0.2798\n",
      "Epoch 95 Batch 100 Loss 0.0833 Accuracy 0.2790\n",
      "Epoch 95 Batch 150 Loss 0.0934 Accuracy 0.2790\n",
      "Epoch 95 Batch 200 Loss 0.1084 Accuracy 0.2779\n",
      "Epoch 95 Loss 0.1297 Accuracy 0.2769\n",
      "Epoch 96 Batch 0 Loss 0.1037 Accuracy 0.3102\n",
      "Epoch 96 Batch 50 Loss 0.0842 Accuracy 0.2783\n",
      "Epoch 96 Batch 100 Loss 0.0912 Accuracy 0.2781\n",
      "Epoch 96 Batch 150 Loss 0.1011 Accuracy 0.2783\n",
      "Epoch 96 Batch 200 Loss 0.1176 Accuracy 0.2773\n",
      "Epoch 96 Loss 0.1365 Accuracy 0.2765\n",
      "Epoch 97 Batch 0 Loss 0.0804 Accuracy 0.2934\n",
      "Epoch 97 Batch 50 Loss 0.0792 Accuracy 0.2783\n",
      "Epoch 97 Batch 100 Loss 0.0880 Accuracy 0.2775\n",
      "Epoch 97 Batch 150 Loss 0.0966 Accuracy 0.2780\n",
      "Epoch 97 Batch 200 Loss 0.1127 Accuracy 0.2775\n",
      "Epoch 97 Loss 0.1332 Accuracy 0.2768\n",
      "Epoch 98 Batch 0 Loss 0.0645 Accuracy 0.2957\n",
      "Epoch 98 Batch 50 Loss 0.0756 Accuracy 0.2793\n",
      "Epoch 98 Batch 100 Loss 0.0848 Accuracy 0.2793\n",
      "Epoch 98 Batch 150 Loss 0.0953 Accuracy 0.2786\n",
      "Epoch 98 Batch 200 Loss 0.1107 Accuracy 0.2782\n",
      "Epoch 98 Loss 0.1322 Accuracy 0.2768\n",
      "Epoch 99 Batch 0 Loss 0.0596 Accuracy 0.2807\n",
      "Epoch 99 Batch 50 Loss 0.0786 Accuracy 0.2787\n",
      "Epoch 99 Batch 100 Loss 0.0871 Accuracy 0.2798\n",
      "Epoch 99 Batch 150 Loss 0.0993 Accuracy 0.2789\n",
      "Epoch 99 Batch 200 Loss 0.1148 Accuracy 0.2779\n",
      "Epoch 99 Loss 0.1350 Accuracy 0.2770\n",
      "Epoch 100 Batch 0 Loss 0.1106 Accuracy 0.2830\n",
      "Epoch 100 Batch 50 Loss 0.0761 Accuracy 0.2812\n",
      "Epoch 100 Batch 100 Loss 0.0836 Accuracy 0.2810\n",
      "Epoch 100 Batch 150 Loss 0.0956 Accuracy 0.2792\n",
      "Epoch 100 Batch 200 Loss 0.1097 Accuracy 0.2777\n",
      "Epoch 100 Loss 0.1312 Accuracy 0.2769\n",
      "CPU times: user 1h 22min, sys: 10min 42s, total: 1h 32min 42s\n",
      "Wall time: 41min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(100):\n",
    "# for epoch in range(2):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "  \n",
    "    for (batch, (inp, tar)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        train_step(inp, tar)\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "    \n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    start_token = [1]\n",
    "    end_token = [2]\n",
    "  \n",
    "    sentence = preprocess_sentence(inp_sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    \n",
    "    encoder_input = tf.expand_dims(inputs, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "    decoder_input = [1]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(max_length_targ):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == targ_lang_tokenizer.word_index[\"<end>\"]:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "\n",
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "    sentence = inp_lang_tokenizer.encode(sentence)\n",
    "  \n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                            if i < tokenizer_en.vocab_size], \n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def translate(sentence, plot=''):\n",
    "    result, attention_weights = evaluate(sentence)\n",
    "    predicted_sentence = ([targ_lang_tokenizer.index_word[i] for i in result.numpy()])  \n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: good morning.\n",
      "Predicted translation: ['<start>', 'утром', 'был', 'ливень', '.']\n"
     ]
    }
   ],
   "source": [
    "translate(\"good morning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: hi\n",
      "Predicted translation: ['<start>', 'привет', '!']\n"
     ]
    }
   ],
   "source": [
    "translate(u\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: hi, how are you?\n",
      "Predicted translation: ['<start>', 'ну', 'что', 'нибудь', ',', 'вы', 'в', 'н', 'м', '?']\n"
     ]
    }
   ],
   "source": [
    "translate('hi, how are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: i'm fine, and you?\n",
      "Predicted translation: ['<start>', 'я', 'в', 'порядке', 'и', '?']\n"
     ]
    }
   ],
   "source": [
    "translate(\"i'm fine, and you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate(\"If two witches were watching two watches which witch would watch which watch\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: president of america\n",
      "Predicted translation: ['<start>', 'о', 'поездке', 'в', 'америку', 'этим', 'летом', 'не', 'может', 'быть', 'и', 'речи', '.']\n"
     ]
    }
   ],
   "source": [
    "translate(\"president of america\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: we are leaving in russia\n",
      "Predicted translation: ['<start>', 'мы', 'уходим', 'в', 'хотела', 'свои', 'что', 'то', 'долго', '.']\n"
     ]
    }
   ],
   "source": [
    "translate(\"we are leaving in russia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Качество перевода оставляет желать гораздо гораздо лучшего.\n",
    "Думаю нужно полностью переработать подачу данных. Во-первых нужно брать все сэмплы из файла, а не часть. При текущей архитектуре попытка увеличить количество сэмплов приводит к Out-of-Memory ошибке.\n",
    "Помимо этого возможно нужно поиграться с архитектурой, а точнее с размерностью слоев, что теоретически может улучшить результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
